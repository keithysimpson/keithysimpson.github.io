<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RT60 Room Reverberation Estimator</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            color: #333;
        }
        h1 {
            text-align: center;
            margin-bottom: 30px;
        }
        .container {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .card {
            background-color: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .controls {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        button {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 12px 20px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 4px;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #45a049;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        .visualization {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
        }
        canvas {
            width: 100%;
            background-color: #fff;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .results {
            margin-top: 20px;
            text-align: center;
        }
        #rt60Value {
            font-size: 24px;
            font-weight: bold;
            color: #4CAF50;
        }
        .instructions {
            margin-bottom: 20px;
            padding: 15px;
            background-color: #e9f7ef;
            border-left: 4px solid #4CAF50;
            border-radius: 4px;
        }
        .frequency-selector {
            margin: 10px 0;
        }
        select {
            padding: 8px;
            border-radius: 4px;
            border: 1px solid #ddd;
        }
        .status {
            text-align: center;
            font-style: italic;
            color: #666;
        }
    </style>
</head>
<body>
    <h1>RT60 Room Reverberation Estimator</h1>
    
    <div class="container">
        <div class="card instructions">
            <h3>How to use:</h3>
            <ol>
                <li>Place your phone in the center of the room</li>
                <li>Make sure the room is quiet</li>
                <li>Select test frequency (or use pink noise)</li>
                <li>Click "Run RT60 Test"</li>
                <li>Stay quiet during the test (about 5 seconds)</li>
                <li>Results will be displayed automatically</li>
            </ol>
        </div>
        
        <div class="card controls">
            <div class="frequency-selector">
                <label for="testSignal">Test signal:</label>
                <select id="testSignal">
                    <option value="pink">Pink Noise</option>
                    <option value="125">125 Hz Tone</option>
                    <option value="250">250 Hz Tone</option>
                    <option value="500">500 Hz Tone</option>
                    <option value="1000">1000 Hz Tone</option>
                    <option value="2000">2000 Hz Tone</option>
                    <option value="4000">4000 Hz Tone</option>
                </select>
            </div>
            <div class="run-count-selector" style="margin: 10px 0;">
                <label for="runCount">Number of runs:</label>
                <input type="number" id="runCount" value="1" min="1" max="10" style="padding: 8px; border-radius: 4px; border: 1px solid #ddd; width: 60px;">
            </div>
            <button id="startButton">Run RT60 Test</button>
            <button id="stopButton" disabled>Stop</button>
            <p id="statusText" class="status">Ready</p>
        </div>
        
        <div class="card visualization">
            <h3>Audio Waveform</h3>
            <canvas id="waveformCanvas" height="150"></canvas>
            <h3>Decay Curve</h3>
            <canvas id="decayCurveCanvas" height="200"></canvas>
        </div>
        
        <div class="card results">
            <h3>RT60 Results</h3>
            <div id="rt60Value">--</div>
            <p id="rt60Description">Run a test to get results</p>
            <div id="multiRunResults" style="margin-top: 15px; text-align: left; max-height: 150px; overflow-y: auto; background-color: #eee; padding: 10px; border-radius: 4px; display: none;">
                <h4>Individual Runs:</h4>
                <ul id="individualResultsList" style="list-style: none; padding: 0;"></ul>
                <p><strong>Average RT60: <span id="averageRt60Value">--</span></strong></p>
            </div>
        </div>
    </div>

    <script>
        // Audio context and variables
        let audioContext;
        let micStream;
        let recorder; // Note: recorder variable is declared but not used. Consider removing.
        let analyzers = {};
        let isRecording = false;
        let audioBuffer = null;
        let testToneNode = null;
        let noiseNode = null;
        let micSource = null; // Make global for cleanup
        let processorNode = null; // Make global for cleanup
        let currentRun = 0;
        let totalRuns = 1;
        let allRt60Results = [];
        let stopRequested = false; // Flag to stop multi-run sequence
        
        // User interface elements
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusText = document.getElementById('statusText');
        const testSignalSelect = document.getElementById('testSignal');
        const runCountInput = document.getElementById('runCount');
        const rt60Value = document.getElementById('rt60Value');
        const rt60Description = document.getElementById('rt60Description');
        const multiRunResultsDiv = document.getElementById('multiRunResults');
        const individualResultsList = document.getElementById('individualResultsList');
        const averageRt60ValueSpan = document.getElementById('averageRt60Value');
        const waveformCanvas = document.getElementById('waveformCanvas');
        const decayCurveCanvas = document.getElementById('decayCurveCanvas');
        const waveformCtx = waveformCanvas.getContext('2d');
        const decayCurveCtx = decayCurveCanvas.getContext('2d');
        
        // Initialize application
        async function initialize() {
            try {
                // Request audio context only once
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }
                
                // Setup canvas sizes
                setupCanvases();
                
                // Setup event listeners
                startButton.addEventListener('click', startMultiRunTest);
                stopButton.addEventListener('click', requestStop); // Use requestStop to handle multi-run interruption
                
                // Draw empty visualizations
                drawEmptyWaveform();
                drawEmptyDecayCurve();
                
                statusText.textContent = "Ready. Click 'Run RT60 Test' to begin.";
            } catch (error) {
                console.error("Error initializing app:", error);
                statusText.textContent = "Error: " + error.message;
                alert("Could not initialize audio. Please ensure microphone access is allowed and refresh the page.");
            }
        }
        
        // Setup canvas dimensions
        function setupCanvases() {
            const dpr = window.devicePixelRatio || 1;
            
            // Waveform canvas
            waveformCanvas.width = waveformCanvas.offsetWidth * dpr;
            waveformCanvas.height = waveformCanvas.offsetHeight * dpr;
            waveformCtx.scale(dpr, dpr);
            
            // Decay curve canvas
            decayCurveCanvas.width = decayCurveCanvas.offsetWidth * dpr;
            decayCurveCanvas.height = decayCurveCanvas.offsetHeight * dpr;
            decayCurveCtx.scale(dpr, dpr);
        }

        // Start the multi-run test sequence
        async function startMultiRunTest() {
            stopRequested = false;
            allRt60Results = [];
            currentRun = 0;
            totalRuns = parseInt(runCountInput.value) || 1;
            if (totalRuns < 1) totalRuns = 1;
            if (totalRuns > 10) totalRuns = 10; // Limit runs
            runCountInput.value = totalRuns; // Update input if adjusted

            // Reset UI for multi-run
            rt60Value.textContent = "--";
            rt60Description.textContent = "Starting tests...";
            multiRunResultsDiv.style.display = 'none';
            individualResultsList.innerHTML = '';
            averageRt60ValueSpan.textContent = '--';
            startButton.disabled = true;
            stopButton.disabled = false;

            for (let i = 0; i < totalRuns; i++) {
                if (stopRequested) {
                    statusText.textContent = "Test sequence stopped by user.";
                    break;
                }
                currentRun = i + 1;
                statusText.textContent = `Starting run ${currentRun} of ${totalRuns}...`;
                
                try {
                    // Ensure audio context is running before each test
                    if (audioContext.state === 'suspended') {
                        await audioContext.resume();
                    }
                    const result = await runSingleTest();
                    if (result !== null && !isNaN(result)) {
                        allRt60Results.push(result);
                        // Display result immediately (optional)
                        // rt60Value.textContent = result.toFixed(2) + "s (Run " + currentRun + ")";
                    } else {
                         individualResultsList.innerHTML += `<li>Run ${currentRun}: Error or invalid result</li>`;
                    }
                    // Add a small delay between runs (optional, helps ensure resources are released)
                    await new Promise(resolve => setTimeout(resolve, 300)); 
                } catch (error) {
                    console.error(`Error during run ${currentRun}:`, error);
                    statusText.textContent = `Error in run ${currentRun}: ${error.message}`;
                    individualResultsList.innerHTML += `<li>Run ${currentRun}: Error (${error.message})</li>`;
                    // Optionally stop the whole sequence on error, or continue
                    // stopRequested = true; // Uncomment to stop on first error
                }
            }

            // Process and display final results
            processMultiRunResults();
            
            // Final cleanup and UI reset
            isRecording = false; // Ensure this is false
            stopTestCleanup(); // Perform final cleanup
            if (!stopRequested) {
                 statusText.textContent = "All tests complete.";
            }
        }

        // Function to run a single RT60 test
        function runSingleTest() {
            return new Promise(async (resolve, reject) => {
                try {
                    if (isRecording) {
                        console.warn("Already recording, skipping new test start.");
                        return reject(new Error("Already recording"));
                    }
                    isRecording = true;
                    audioBuffer = null; // Reset previous buffer

                    // Update status for the current run
                    statusText.textContent = `Run ${currentRun}/${totalRuns}: Requesting microphone...`;

                    // Get microphone access
                    micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    
                    // Create microphone source
                    micSource = audioContext.createMediaStreamSource(micStream);
                    
                    // Setup analyzer for microphone input (optional, keep if waveform needed during recording)
                    const analyzer = audioContext.createAnalyser();
                    analyzer.fftSize = 2048;
                    micSource.connect(analyzer);
                    analyzers.mic = analyzer; // Store if needed elsewhere
                    
                    // Setup recorder
                    const recordingLength = 5; // seconds
                    const sampleRate = audioContext.sampleRate;
                    const bufferSize = recordingLength * sampleRate;
                    let recordedData = new Float32Array(bufferSize);
                    let recordingPosition = 0;
                    
                    // Create script processor for recording
                    // Ensure previous node is disconnected if somehow exists (shouldn't with proper cleanup)
                    if (processorNode) {
                        processorNode.disconnect();
                        processorNode = null;
                    }
                    processorNode = audioContext.createScriptProcessor(4096, 1, 1);
                    
                    processorNode.onaudioprocess = function(e) {
                        if (!isRecording) return; // Check recording flag
                        
                        const input = e.inputBuffer.getChannelData(0);
                        
                        // Copy input data to recording buffer
                        if (recordingPosition + input.length <= recordedData.length) {
                            recordedData.set(input, recordingPosition);
                            recordingPosition += input.length;
                            
                            // Update status
                            const progress = Math.min(100, Math.round((recordingPosition / recordedData.length) * 100));
                            statusText.textContent = `Run ${currentRun}/${totalRuns}: Recording... ${progress}%`;
                            
                            // Visualize waveform (optional during recording)
                            drawWaveform(input);
                        } else {
                            // Recording complete for this run
                            isRecording = false; // Set flag immediately
                            
                            // Disconnect processor node *before* processing to prevent further events
                            if (processorNode) {
                                processorNode.disconnect(); 
                                // processorNode = null; // Keep reference until cleanup? No, disconnect is enough.
                            }
                            if (micSource) {
                                micSource.disconnect(); // Disconnect source as well
                            }
                             // Stop mic stream tracks *after* processing node is done
                            if (micStream) {
                                micStream.getTracks().forEach(track => track.stop());
                                micStream = null;
                            }

                            statusText.textContent = `Run ${currentRun}/${totalRuns}: Processing...`;
                            
                            // Create audio buffer from recorded data
                            audioBuffer = audioContext.createBuffer(1, recordedData.length, sampleRate);
                            audioBuffer.getChannelData(0).set(recordedData.slice(0, recordingPosition)); // Use actual recorded length

                            // Process the recorded audio for RT60
                            const rt60 = processRT60(audioBuffer);
                            resolve(rt60); // Resolve the promise with the result
                        }
                    };
                    
                    micSource.connect(processorNode);
                    processorNode.connect(audioContext.destination); // Connect to destination to keep graph alive
                    
                    // Create and play test signal
                    const testSignal = testSignalSelect.value;
                    statusText.textContent = `Run ${currentRun}/${totalRuns}: Playing test signal...`;
                    
                    // Set up a small delay before starting the test signal
                    setTimeout(() => {
                        if (!isRecording) return; // Check if stopped before signal plays
                        if (testSignal === 'pink') {
                            playPinkNoise(0.5); // 0.5 seconds
                        } else {
                            const frequency = parseInt(testSignal);
                            playTestTone(frequency, 0.5); // 0.5 seconds
                        }
                        
                        // Update status
                        statusText.textContent = `Run ${currentRun}/${totalRuns}: Recording room response...`;
                    }, 500); // Delay before playing sound
                    
                } catch (error) {
                    console.error(`Error during single test run ${currentRun}:`, error);
                    statusText.textContent = `Error in run ${currentRun}: ${error.message}`;
                    isRecording = false; // Ensure flag is reset on error
                    stopTestCleanup(); // Clean up resources on error
                    reject(error); // Reject the promise
                }
            });
        }

        // Generate and play a test tone
        function playTestTone(frequency, duration) {
            // Create oscillator
            testToneNode = audioContext.createOscillator();
            testToneNode.type = 'sine';
            testToneNode.frequency.value = frequency;
            
            // Create gain node for envelope
            const gainNode = audioContext.createGain();
            gainNode.gain.value = 0;
            
            // Connect nodes
            testToneNode.connect(gainNode);
            gainNode.connect(audioContext.destination);
            
            // Start oscillator
            testToneNode.start();
            
            // Apply envelope
            const now = audioContext.currentTime;
            gainNode.gain.setValueAtTime(0, now);
            gainNode.gain.linearRampToValueAtTime(0.7, now + 0.01); // Quick fade in
            gainNode.gain.setValueAtTime(0.7, now + duration - 0.05);
            gainNode.gain.linearRampToValueAtTime(0, now + duration); // Quick fade out
            
            // Stop oscillator after duration
            testToneNode.stop(now + duration + 0.1);
            
            // Clean up
            testToneNode.onended = function() {
                testToneNode.disconnect();
                gainNode.disconnect();
                testToneNode = null;
            };
        }
        
        // Generate and play pink noise
        function playPinkNoise(duration) {
            // Create buffer for noise
            const bufferSize = audioContext.sampleRate * duration;
            const noiseBuffer = audioContext.createBuffer(1, bufferSize, audioContext.sampleRate);
            const output = noiseBuffer.getChannelData(0);
            
            // Generate pink noise using Paul Kellet's method
            let b0 = 0, b1 = 0, b2 = 0, b3 = 0, b4 = 0, b5 = 0, b6 = 0;
            
            for (let i = 0; i < bufferSize; i++) {
                // White noise
                const white = Math.random() * 2 - 1;
                
                // Pink noise filter
                b0 = 0.99886 * b0 + white * 0.0555179;
                b1 = 0.99332 * b1 + white * 0.0750759;
                b2 = 0.96900 * b2 + white * 0.1538520;
                b3 = 0.86650 * b3 + white * 0.3104856;
                b4 = 0.55000 * b4 + white * 0.5329522;
                b5 = -0.7616 * b5 - white * 0.0168980;
                
                // Combine filter outputs
                output[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;
                
                // Scale to keep in range [-1, 1]
                output[i] *= 0.11;
            }
            
            // Create source node
            noiseNode = audioContext.createBufferSource();
            noiseNode.buffer = noiseBuffer;
            
            // Create gain node for envelope
            const gainNode = audioContext.createGain();
            gainNode.gain.value = 0;
            
            // Connect nodes
            noiseNode.connect(gainNode);
            gainNode.connect(audioContext.destination);
            
            // Start noise
            noiseNode.start();
            
            // Apply envelope
            const now = audioContext.currentTime;
            gainNode.gain.setValueAtTime(0, now);
            gainNode.gain.linearRampToValueAtTime(0.7, now + 0.01); // Quick fade in
            gainNode.gain.setValueAtTime(0.7, now + duration - 0.05);
            gainNode.gain.linearRampToValueAtTime(0, now + duration); // Quick fade out
            
            // Stop noise after duration
            noiseNode.stop(now + duration + 0.1);
            
            // Clean up
            noiseNode.onended = function() {
                noiseNode.disconnect();
                gainNode.disconnect();
                noiseNode = null;
            };
        }
        
        // Process audio to calculate RT60 - returns the value
        function processRT60(buffer) {
            // Get audio data
            const audioData = buffer.getChannelData(0);
            const sampleRate = buffer.sampleRate;
            
            // Calculate energy over time (using RMS in small windows)
            const windowSize = Math.floor(sampleRate * 0.03); // 30ms windows
            const numWindows = Math.floor(audioData.length / windowSize);
            const energyProfile = [];
            
            for (let i = 0; i < numWindows; i++) {
                let sum = 0;
                const offset = i * windowSize;
                
                for (let j = 0; j < windowSize; j++) {
                    if (offset + j < audioData.length) {
                        // Square the sample (for energy)
                        sum += audioData[offset + j] * audioData[offset + j];
                    }
                }
                
                // Calculate RMS for this window
                const rms = Math.sqrt(sum / windowSize);
                
                // Convert to dB
                const energy_db = 20 * Math.log10(Math.max(rms, 1e-10));
                
                energyProfile.push({
                    time: i * (windowSize / sampleRate),
                    energy: energy_db
                });
            }
            
            // Find the peak in the energy profile
            let peakEnergy = -Infinity;
            let peakIndex = 0;
            
            for (let i = 0; i < energyProfile.length; i++) {
                if (energyProfile[i].energy > peakEnergy) {
                    peakEnergy = energyProfile[i].energy;
                    peakIndex = i;
                }
            }
            
            // Only consider the decay portion (after the peak)
            const decayProfile = energyProfile.slice(peakIndex);
            
            // Normalize dB values relative to peak
            for (let i = 0; i < decayProfile.length; i++) {
                decayProfile[i].energy = decayProfile[i].energy - peakEnergy;
            }
            
            // Find -5dB and -25dB points for RT60 calculation
            // (Using -5dB to -25dB drop to avoid direct sound and noise floor)
            let index5dB = null;
            let index25dB = null;
            
            for (let i = 0; i < decayProfile.length; i++) {
                if (index5dB === null && decayProfile[i].energy <= -5) {
                    index5dB = i;
                }
                if (index25dB === null && decayProfile[i].energy <= -25) {
                    index25dB = i;
                    break;
                }
            }
            
            // Calculate RT60 value (extrapolating from -5dB to -25dB to get -60dB)
            let rt60 = 0; // Initialize rt60
            if (index5dB !== null && index25dB !== null && index25dB > index5dB) { // Add check index25dB > index5dB
                const time5dB = decayProfile[index5dB].time;
                const time25dB = decayProfile[index25dB].time;
                const timeFor20dBDecay = time25dB - time5dB;
                if (timeFor20dBDecay > 0) { // Avoid division by zero or negative time
                   rt60 = (timeFor20dBDecay / 20) * 60; // Scale to 60dB decay
                } else {
                    console.warn("T20 calculation resulted in non-positive time difference.");
                    rt60 = estimateRT60FromDecay(decayProfile); // Fallback if times are weird
                }
            } else {
                // If we couldn't find the points, make an estimate based on available data
                rt60 = estimateRT60FromDecay(decayProfile);
            }

            // Draw the decay curve for the *last* processed buffer
            drawDecayCurve(decayProfile); 

            // Return the calculated value
            if (rt60 > 0 && !isNaN(rt60)) {
                 return rt60;
            } else {
                console.warn("RT60 calculation failed or resulted in zero/NaN.");
                return null; // Indicate failure
            }
        }

        // Function to process and display results after all runs
        function processMultiRunResults() {
            if (allRt60Results.length === 0) {
                rt60Value.textContent = "Error";
                rt60Description.textContent = "No valid results obtained.";
                multiRunResultsDiv.style.display = 'none';
                return;
            }

            let sum = 0;
            individualResultsList.innerHTML = ''; // Clear previous list items
            allRt60Results.forEach((result, index) => {
                sum += result;
                const listItem = document.createElement('li');
                listItem.textContent = `Run ${index + 1}: ${result.toFixed(2)}s`;
                individualResultsList.appendChild(listItem);
            });

            const averageRt60 = sum / allRt60Results.length;

            // Display average result prominently
            rt60Value.textContent = averageRt60.toFixed(2) + "s (Average)";
            rt60Description.textContent = getRt60Description(averageRt60); // Use helper for description

            // Show multi-run details
            averageRt60ValueSpan.textContent = averageRt60.toFixed(2) + "s";
            multiRunResultsDiv.style.display = 'block';
        }

        // Helper function to get description text based on RT60 value
        function getRt60Description(rt60) {
            if (rt60 < 0.3) return "Very dry room, highly damped (like a recording studio)";
            if (rt60 < 0.5) return "Well damped room, good for speech clarity";
            if (rt60 < 0.8) return "Balanced acoustics, good for music and speech";
            if (rt60 < 1.2) return "Live room, favorable for music";
            if (rt60 < 2.0) return "Very reverberant space (like a concert hall)";
            return "Extremely reverberant (like a cathedral)";
        }
        
        // Estimate RT60 when standard points aren't available
        function estimateRT60FromDecay(decayProfile) {
            // Find the linear regression line for the decay
            let sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
            let n = 0;
            
            // Only use points that are below -3dB and above -40dB for better fit
            const validPoints = decayProfile.filter(p => p.energy < -3 && p.energy > -40);
            
            if (validPoints.length < 10) {
                return 0; // Not enough points for a good estimate
            }
            
            n = validPoints.length;
            
            for (let i = 0; i < n; i++) {
                sumX += validPoints[i].time;
                sumY += validPoints[i].energy;
                sumXY += validPoints[i].time * validPoints[i].energy;
                sumX2 += validPoints[i].time * validPoints[i].time;
            }
            
            // Calculate slope of regression line
            const slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);
            
            // Slope gives dB/second, so calculate how many seconds for -60dB
            if (slope < 0) {
                return Math.abs(60 / slope);
            } else {
                return 0; // Positive slope means no decay
            }
        }
        
        // Request stop - sets flag for multi-run loop and calls cleanup
        function requestStop() {
            statusText.textContent = "Stop requested...";
            stopRequested = true;
            isRecording = false; // Force recording stop
            
            // Immediately try to stop any active sound generation
             if (testToneNode) {
                try { testToneNode.stop(); } catch(e) {}
                testToneNode = null;
            }
            if (noiseNode) {
                 try { noiseNode.stop(); } catch(e) {}
                noiseNode = null;
            }

            // Call cleanup function
            stopTestCleanup();
        }

        // Cleanup function for resources - safe to call multiple times
        function stopTestCleanup() {
            isRecording = false; // Ensure flag is false

            // Stop microphone stream tracks
            if (micStream) {
                micStream.getTracks().forEach(track => track.stop());
                micStream = null;
            }

            // Disconnect audio nodes
            if (micSource) {
                try { micSource.disconnect(); } catch(e) {}
                micSource = null;
            }
            if (processorNode) {
                 try { processorNode.disconnect(); } catch(e) {}
                processorNode = null; 
            }
             // Stop test tone/noise again just in case
            if (testToneNode) {
                try { testToneNode.stop(); } catch(e) {}
                testToneNode = null;
            }
            if (noiseNode) {
                 try { noiseNode.stop(); } catch(e) {}
                noiseNode = null;
            }
            
            // Reset UI
            startButton.disabled = false;
            stopButton.disabled = true;
            
            // Don't overwrite final status messages like "All tests complete" or "Error"
             if (statusText.textContent.startsWith("Run") || statusText.textContent.startsWith("Starting") || statusText.textContent.startsWith("Recording") || statusText.textContent.startsWith("Playing") || statusText.textContent.startsWith("Requesting")) {
                 statusText.textContent = "Test stopped.";
             }
        }
        
        // Draw the waveform visualization
        function drawWaveform(data) {
            const width = waveformCanvas.width;
            const height = waveformCanvas.height;
            const ctx = waveformCtx;
            
            // Clear canvas
            ctx.clearRect(0, 0, width, height);
            
            // Set style
            ctx.lineWidth = 2;
            ctx.strokeStyle = '#4CAF50';
            
            // Draw waveform
            const sliceWidth = width / data.length;
            let x = 0;
            
            ctx.beginPath();
            ctx.moveTo(0, height / 2);
            
            for (let i = 0; i < data.length; i++) {
                const y = (data[i] * height / 2) + (height / 2);
                ctx.lineTo(x, y);
                x += sliceWidth;
            }
            
            ctx.lineTo(width, height / 2);
            ctx.stroke();
        }
        
        // Draw empty waveform
        function drawEmptyWaveform() {
            const width = waveformCanvas.width;
            const height = waveformCanvas.height;
            const ctx = waveformCtx;
            
            // Clear canvas
            ctx.clearRect(0, 0, width, height);
            
            // Draw center line
            ctx.beginPath();
            ctx.moveTo(0, height / 2);
            ctx.lineTo(width, height / 2);
            ctx.strokeStyle = '#ddd';
            ctx.stroke();
            
            // Text
            ctx.font = '14px sans-serif';
            ctx.fillStyle = '#999';
            ctx.textAlign = 'center';
            ctx.fillText('Waveform will appear here during recording', width / 2, height / 2 - 15);
        }
        
        // Draw the decay curve - minor update to handle potential empty profile better
        function drawDecayCurve(decayProfile) {
            const width = decayCurveCanvas.width;
            const height = decayCurveCanvas.height;
            const ctx = decayCurveCtx;
            const padding = 30; // Padding for labels
            
            // Clear canvas
            ctx.clearRect(0, 0, width, height);
            
            // If no data or not enough data, show message
            if (!decayProfile || decayProfile.length < 2) { // Need at least 2 points to draw a line
                drawEmptyDecayCurve(); // Use the empty state drawing function
                return;
            }
            
            // Calculate scale
            const graphWidth = width - padding * 2;
            const graphHeight = height - padding * 2;
            
            // Find max time
            const maxTime = decayProfile[decayProfile.length - 1].time;
             // Ensure maxTime is positive to avoid drawing issues
            if (maxTime <= 0) {
                 drawEmptyDecayCurve();
                 return;
            }

            // Draw axes
            ctx.beginPath();
            ctx.moveTo(padding, padding);
            ctx.lineTo(padding, height - padding);
            ctx.lineTo(width - padding, height - padding);
            ctx.strokeStyle = '#666';
            ctx.lineWidth = 1;
            ctx.stroke();
            
            // Draw y-axis labels (dB)
            ctx.font = '10px sans-serif';
            ctx.fillStyle = '#666';
            ctx.textAlign = 'right';
            ctx.textBaseline = 'middle';
            
            for (let db = 0; db >= -60; db -= 10) {
                const y = padding + (graphHeight * Math.abs(db) / 60);
                
                ctx.beginPath();
                ctx.moveTo(padding - 5, y);
                ctx.lineTo(padding, y);
                ctx.stroke();
                
                ctx.fillText(db + ' dB', padding - 8, y);
            }
            
            // Draw x-axis labels (time)
            ctx.textAlign = 'center';
            ctx.textBaseline = 'top';
            
            for (let t = 0; t <= maxTime; t += Math.max(0.5, Math.ceil(maxTime / 5))) {
                const x = padding + (graphWidth * t / maxTime);
                
                ctx.beginPath();
                ctx.moveTo(x, height - padding);
                ctx.lineTo(x, height - padding + 5);
                ctx.stroke();
                
                ctx.fillText(t.toFixed(1) + 's', x, height - padding + 8);
            }
            
            // Draw decay curve
            ctx.beginPath();
            let firstPoint = true;
            
            for (let i = 0; i < decayProfile.length; i++) {
                const point = decayProfile[i];
                const x = padding + (graphWidth * point.time / maxTime);
                const y = padding + (graphHeight * Math.min(60, Math.abs(point.energy)) / 60);
                
                if (firstPoint) {
                    ctx.moveTo(x, y);
                    firstPoint = false;
                } else {
                    ctx.lineTo(x, y);
                }
            }
            
            ctx.strokeStyle = '#4CAF50';
            ctx.lineWidth = 2;
            ctx.stroke();
            
            // Draw lines at -5dB and -25dB (RT60 calculation points)
            ctx.beginPath();
            ctx.moveTo(padding, padding + (graphHeight * 5 / 60));
            ctx.lineTo(width - padding, padding + (graphHeight * 5 / 60));
            ctx.moveTo(padding, padding + (graphHeight * 25 / 60));
            ctx.lineTo(width - padding, padding + (graphHeight * 25 / 60));
            ctx.strokeStyle = 'rgba(255, 0, 0, 0.5)';
            ctx.lineWidth = 1;
            ctx.setLineDash([5, 5]);
            ctx.stroke();
            ctx.setLineDash([]);
            
            // Label the reference lines
            ctx.fillStyle = 'rgba(255, 0, 0, 0.7)';
            ctx.textAlign = 'left';
            ctx.fillText('-5 dB', padding + 5, padding + (graphHeight * 5 / 60) - 5);
            ctx.fillText('-25 dB', padding + 5, padding + (graphHeight * 25 / 60) - 5);
        }
        
        // Draw empty decay curve
        function drawEmptyDecayCurve() {
            const width = decayCurveCanvas.width;
            const height = decayCurveCanvas.height;
            const ctx = decayCurveCtx;
            const padding = 30;
            
            // Clear canvas
            ctx.clearRect(0, 0, width, height);
            
            // Draw axes
            ctx.beginPath();
            ctx.moveTo(padding, padding);
            ctx.lineTo(padding, height - padding);
            ctx.lineTo(width - padding, height - padding);
            ctx.strokeStyle = '#ddd';
            ctx.lineWidth = 1;
            ctx.stroke();
            
            // Text
            ctx.font = '14px sans-serif';
            ctx.fillStyle = '#999';
            ctx.textAlign = 'center';
            ctx.fillText('Decay curve will appear here after testing', width / 2, height / 2);
        }
        
        // Handle window resize
        window.addEventListener('resize', function() {
            setupCanvases();
            // Redraw based on the *last* calculated decay profile if available
            // This part is tricky as decayProfile is local to processRT60 now.
            // We might need to store the last valid decayProfile globally if redraw on resize is critical.
            // For now, let's just redraw empty state or potentially the last audioBuffer's waveform.
            if (audioBuffer) {
                 // Option 1: Redraw last decay curve (requires storing decayProfile globally)
                 // if (lastDecayProfile) drawDecayCurve(lastDecayProfile); 
                 // else drawEmptyDecayCurve();

                 // Option 2: Just draw empty curves on resize for simplicity after multi-run
                 drawEmptyWaveform(); 
                 drawEmptyDecayCurve();
            } else {
                drawEmptyWaveform();
                drawEmptyDecayCurve();
            }
        });
        
        // Initialize on load
        window.addEventListener('load', initialize);
    </script>
</body>
</html>